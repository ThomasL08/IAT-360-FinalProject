{
  "best_metric": 0.44095760583877563,
  "best_model_checkpoint": "./results\\checkpoint-4000",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 2.6954517364501953,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 1.3764,
      "step": 100
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.190955877304077,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 1.3291,
      "step": 200
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.0754318237304688,
      "learning_rate": 3e-06,
      "loss": 1.2388,
      "step": 300
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.6684491634368896,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.0937,
      "step": 400
    },
    {
      "epoch": 0.25,
      "grad_norm": 17.670848846435547,
      "learning_rate": 5e-06,
      "loss": 0.9716,
      "step": 500
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.60099983215332,
      "learning_rate": 6e-06,
      "loss": 0.8647,
      "step": 600
    },
    {
      "epoch": 0.35,
      "grad_norm": 26.751033782958984,
      "learning_rate": 7e-06,
      "loss": 0.8117,
      "step": 700
    },
    {
      "epoch": 0.4,
      "grad_norm": 9.41777229309082,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.7378,
      "step": 800
    },
    {
      "epoch": 0.45,
      "grad_norm": 11.604828834533691,
      "learning_rate": 9e-06,
      "loss": 0.6908,
      "step": 900
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.452360153198242,
      "learning_rate": 1e-05,
      "loss": 0.6647,
      "step": 1000
    },
    {
      "epoch": 0.55,
      "grad_norm": 8.570209503173828,
      "learning_rate": 9.88888888888889e-06,
      "loss": 0.6594,
      "step": 1100
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.908777236938477,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.5705,
      "step": 1200
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.292137145996094,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.5739,
      "step": 1300
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.5727591514587402,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.5186,
      "step": 1400
    },
    {
      "epoch": 0.75,
      "grad_norm": 9.04386043548584,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.5232,
      "step": 1500
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.753021240234375,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.5758,
      "step": 1600
    },
    {
      "epoch": 0.85,
      "grad_norm": 11.384302139282227,
      "learning_rate": 9.222222222222224e-06,
      "loss": 0.5202,
      "step": 1700
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.9960975646972656,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.5267,
      "step": 1800
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.844820499420166,
      "learning_rate": 9e-06,
      "loss": 0.5027,
      "step": 1900
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.707622051239014,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.4794,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.818,
      "eval_f1": 0.8126275199122073,
      "eval_loss": 0.46656641364097595,
      "eval_precision": 0.8324543940690019,
      "eval_recall": 0.818,
      "eval_runtime": 19.305,
      "eval_samples_per_second": 103.6,
      "eval_steps_per_second": 12.95,
      "step": 2000
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.8745646476745605,
      "learning_rate": 8.777777777777778e-06,
      "loss": 0.4242,
      "step": 2100
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.167743682861328,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.3887,
      "step": 2200
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.760629177093506,
      "learning_rate": 8.555555555555556e-06,
      "loss": 0.4445,
      "step": 2300
    },
    {
      "epoch": 1.2,
      "grad_norm": 25.64740562438965,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.4344,
      "step": 2400
    },
    {
      "epoch": 1.25,
      "grad_norm": 14.5564546585083,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.4402,
      "step": 2500
    },
    {
      "epoch": 1.3,
      "grad_norm": 24.66094970703125,
      "learning_rate": 8.222222222222222e-06,
      "loss": 0.4659,
      "step": 2600
    },
    {
      "epoch": 1.35,
      "grad_norm": 4.973907947540283,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.4565,
      "step": 2700
    },
    {
      "epoch": 1.4,
      "grad_norm": 10.854835510253906,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.469,
      "step": 2800
    },
    {
      "epoch": 1.45,
      "grad_norm": 10.493134498596191,
      "learning_rate": 7.88888888888889e-06,
      "loss": 0.4138,
      "step": 2900
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.321065902709961,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.4147,
      "step": 3000
    },
    {
      "epoch": 1.55,
      "grad_norm": 17.42605972290039,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.4072,
      "step": 3100
    },
    {
      "epoch": 1.6,
      "grad_norm": 6.100841999053955,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.4319,
      "step": 3200
    },
    {
      "epoch": 1.65,
      "grad_norm": 8.847728729248047,
      "learning_rate": 7.444444444444445e-06,
      "loss": 0.3499,
      "step": 3300
    },
    {
      "epoch": 1.7,
      "grad_norm": 13.428616523742676,
      "learning_rate": 7.333333333333333e-06,
      "loss": 0.4043,
      "step": 3400
    },
    {
      "epoch": 1.75,
      "grad_norm": 15.777664184570312,
      "learning_rate": 7.222222222222223e-06,
      "loss": 0.4382,
      "step": 3500
    },
    {
      "epoch": 1.8,
      "grad_norm": 9.55049991607666,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.3966,
      "step": 3600
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.316418647766113,
      "learning_rate": 7e-06,
      "loss": 0.5052,
      "step": 3700
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.3295295238494873,
      "learning_rate": 6.88888888888889e-06,
      "loss": 0.3952,
      "step": 3800
    },
    {
      "epoch": 1.95,
      "grad_norm": 13.107010841369629,
      "learning_rate": 6.777777777777779e-06,
      "loss": 0.3973,
      "step": 3900
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.103921413421631,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.368,
      "step": 4000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.834,
      "eval_f1": 0.8326598672447324,
      "eval_loss": 0.44095760583877563,
      "eval_precision": 0.8320488472477835,
      "eval_recall": 0.834,
      "eval_runtime": 19.3877,
      "eval_samples_per_second": 103.158,
      "eval_steps_per_second": 12.895,
      "step": 4000
    },
    {
      "epoch": 2.05,
      "grad_norm": 12.852974891662598,
      "learning_rate": 6.555555555555556e-06,
      "loss": 0.3648,
      "step": 4100
    },
    {
      "epoch": 2.1,
      "grad_norm": 9.148959159851074,
      "learning_rate": 6.444444444444445e-06,
      "loss": 0.4122,
      "step": 4200
    },
    {
      "epoch": 2.15,
      "grad_norm": 10.420405387878418,
      "learning_rate": 6.333333333333333e-06,
      "loss": 0.3531,
      "step": 4300
    },
    {
      "epoch": 2.2,
      "grad_norm": 14.805049896240234,
      "learning_rate": 6.222222222222223e-06,
      "loss": 0.312,
      "step": 4400
    },
    {
      "epoch": 2.25,
      "grad_norm": 5.178976058959961,
      "learning_rate": 6.111111111111112e-06,
      "loss": 0.364,
      "step": 4500
    },
    {
      "epoch": 2.3,
      "grad_norm": 8.723848342895508,
      "learning_rate": 6e-06,
      "loss": 0.3585,
      "step": 4600
    },
    {
      "epoch": 2.35,
      "grad_norm": 10.962675094604492,
      "learning_rate": 5.88888888888889e-06,
      "loss": 0.3819,
      "step": 4700
    },
    {
      "epoch": 2.4,
      "grad_norm": 4.833119869232178,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.3808,
      "step": 4800
    },
    {
      "epoch": 2.45,
      "grad_norm": 6.971606254577637,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.3414,
      "step": 4900
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.7701547145843506,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.2842,
      "step": 5000
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.061359405517578,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.3351,
      "step": 5100
    },
    {
      "epoch": 2.6,
      "grad_norm": 8.50964641571045,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.3369,
      "step": 5200
    },
    {
      "epoch": 2.65,
      "grad_norm": 13.423866271972656,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.289,
      "step": 5300
    },
    {
      "epoch": 2.7,
      "grad_norm": 16.584657669067383,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.3879,
      "step": 5400
    },
    {
      "epoch": 2.75,
      "grad_norm": 8.236998558044434,
      "learning_rate": 5e-06,
      "loss": 0.3214,
      "step": 5500
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.12754487991333,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.3267,
      "step": 5600
    },
    {
      "epoch": 2.85,
      "grad_norm": 12.139294624328613,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.3669,
      "step": 5700
    },
    {
      "epoch": 2.9,
      "grad_norm": 21.780048370361328,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.3249,
      "step": 5800
    },
    {
      "epoch": 2.95,
      "grad_norm": 20.748498916625977,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.3692,
      "step": 5900
    },
    {
      "epoch": 3.0,
      "grad_norm": 8.966632843017578,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.2864,
      "step": 6000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8415,
      "eval_f1": 0.8374798724174941,
      "eval_loss": 0.4694523215293884,
      "eval_precision": 0.8489532929829632,
      "eval_recall": 0.8415,
      "eval_runtime": 19.3743,
      "eval_samples_per_second": 103.23,
      "eval_steps_per_second": 12.904,
      "step": 6000
    },
    {
      "epoch": 3.05,
      "grad_norm": 4.080946922302246,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.323,
      "step": 6100
    },
    {
      "epoch": 3.1,
      "grad_norm": 8.026693344116211,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.3075,
      "step": 6200
    },
    {
      "epoch": 3.15,
      "grad_norm": 9.235125541687012,
      "learning_rate": 4.111111111111111e-06,
      "loss": 0.3098,
      "step": 6300
    },
    {
      "epoch": 3.2,
      "grad_norm": 22.949934005737305,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2556,
      "step": 6400
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.9456639885902405,
      "learning_rate": 3.88888888888889e-06,
      "loss": 0.2421,
      "step": 6500
    },
    {
      "epoch": 3.3,
      "grad_norm": 5.45622444152832,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.2539,
      "step": 6600
    },
    {
      "epoch": 3.35,
      "grad_norm": 17.553579330444336,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 0.2934,
      "step": 6700
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.5702236890792847,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.3016,
      "step": 6800
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.11992458999156952,
      "learning_rate": 3.444444444444445e-06,
      "loss": 0.3207,
      "step": 6900
    },
    {
      "epoch": 3.5,
      "grad_norm": 17.22294807434082,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2791,
      "step": 7000
    },
    {
      "epoch": 3.55,
      "grad_norm": 17.81415557861328,
      "learning_rate": 3.2222222222222227e-06,
      "loss": 0.3015,
      "step": 7100
    },
    {
      "epoch": 3.6,
      "grad_norm": 11.397525787353516,
      "learning_rate": 3.1111111111111116e-06,
      "loss": 0.3208,
      "step": 7200
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.30419638752937317,
      "learning_rate": 3e-06,
      "loss": 0.2307,
      "step": 7300
    },
    {
      "epoch": 3.7,
      "grad_norm": 5.408337593078613,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.2535,
      "step": 7400
    },
    {
      "epoch": 3.75,
      "grad_norm": 4.835587978363037,
      "learning_rate": 2.7777777777777783e-06,
      "loss": 0.3345,
      "step": 7500
    },
    {
      "epoch": 3.8,
      "grad_norm": 13.707748413085938,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.2361,
      "step": 7600
    },
    {
      "epoch": 3.85,
      "grad_norm": 8.670412063598633,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.2767,
      "step": 7700
    },
    {
      "epoch": 3.9,
      "grad_norm": 12.64794921875,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 0.3343,
      "step": 7800
    },
    {
      "epoch": 3.95,
      "grad_norm": 6.735638618469238,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.2991,
      "step": 7900
    },
    {
      "epoch": 4.0,
      "grad_norm": 15.954249382019043,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.2609,
      "step": 8000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8445,
      "eval_f1": 0.8432895920561455,
      "eval_loss": 0.47902655601501465,
      "eval_precision": 0.843020826842547,
      "eval_recall": 0.8445,
      "eval_runtime": 19.4719,
      "eval_samples_per_second": 102.712,
      "eval_steps_per_second": 12.839,
      "step": 8000
    }
  ],
  "logging_steps": 100,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8478215897088000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
